<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3c.org/TR/1999/REC-html401-19991224/loose.dtd">
<!-- saved from url=(0032)http://decisiontrees.net/node/35 -->
<HTML lang=en xml:lang="en" xmlns="http://www.w3.org/1999/xhtml"><HEAD><TITLE>Tutorial (11): Evaluating Decision Trees | Decision Trees</TITLE>
<META http-equiv=Content-Style-Type content=text/css>
<META http-equiv=Content-Type content="text/html; charset=utf-8">
<STYLE type=text/css media=all>@import url( misc/drupal.css );
</STYLE>

<STYLE type=text/css media=all>@import url( themes/friendselectric/style.css );
</STYLE>

<SCRIPT type=text/javascript> </SCRIPT>

<META content="MSHTML 6.00.2900.2873" name=GENERATOR></HEAD>
<BODY>
<DIV class=bw1>
<DIV class=bw2>
<DIV id=body-wrap>
<DIV id=header>
<DIV class=hw1>
<DIV class=hw2><A title="Index Page" href="http://decisiontrees.net/"><IMG 
id=site-logo alt=Logo 
src="Tutorial (11) Evaluating Decision Trees  Decision Trees_files/logo.png"></A> 

<H1 class=without-slogan id=site-name><A title="Index Page" 
href="http://decisiontrees.net/">Decision Trees</A></H1>
<DIV id=top-nav>
<UL id=primary>
  <LI><A title="Interactive tutorial" 
  href="http://decisiontrees.net/node/16"><SPAN class=lw1><SPAN 
  class=lw2>Tutorial</SPAN></SPAN></A> </LI>
  <LI><A title=Books href="http://decisiontrees.net/node/19"><SPAN 
  class=lw1><SPAN class=lw2>Books</SPAN></SPAN></A> </LI>
  <LI><A title=Software href="http://decisiontrees.net/node/22"><SPAN 
  class=lw1><SPAN class=lw2>Software</SPAN></SPAN></A> </LI>
  <LI><A title=Sites href="http://decisiontrees.net/node/23"><SPAN 
  class=lw1><SPAN class=lw2>Sites</SPAN></SPAN></A> </LI>
  <LI><A title=Papers href="http://decisiontrees.net/node/45"><SPAN 
  class=lw1><SPAN class=lw2>Papers</SPAN></SPAN></A> </LI>
  <LI><A title=Forums href="http://decisiontrees.net/forum"><SPAN 
  class=lw1><SPAN class=lw2>Forums</SPAN></SPAN></A> </LI>
  <LI><A title=About href="http://decisiontrees.net/node/42"><SPAN 
  class=lw1><SPAN class=lw2>About</SPAN></SPAN></A> 
</LI></UL></DIV></DIV></DIV></DIV>
<DIV class=content-both id=content>
<DIV class=cw1>
<DIV class=cw2>
<DIV class=cw3>
<DIV class=cw4>
<DIV class=cw5>
<DIV class=cw6>
<DIV class=cw7>
<DIV class=cw8>
<DIV class=content-wrap-both id=content-wrap>
<DIV class=sidebar id=sidebar-left>
<DIV class="block block-user" id=block-user-0>
<H2 class=first>User login</H2>
<DIV class=content>
<FORM action=user/login?destination=node%2F35 method=post>
<DIV class=user-login-block>
<DIV class=form-item><LABEL for=edit-name>Username:</LABEL><BR><INPUT 
class=form-text id=edit-name maxLength=64 size=15 name=edit[name]> </DIV>
<DIV class=form-item><LABEL for=edit-pass>Password:</LABEL><BR><INPUT 
class=form-password id=edit-pass type=password maxLength=64 size=15 
name=edit[pass]> </DIV><INPUT class=form-submit type=submit value="Log in" name=op> </DIV></FORM>
<DIV class=item-list>
<UL>
  <LI><A title="Create a new user account." 
  href="http://decisiontrees.net/user/register">Create new account</A>
  <LI><A title="Request new password via e-mail." 
  href="http://decisiontrees.net/user/password">Request new 
password</A></LI></UL></DIV></DIV></DIV>
<DIV class="block block-book" id=block-book-0>
<H2>Tutorial</H2>
<DIV class=content>
<DIV class=menu>
<UL>
  <LI class=leaf><A href="http://decisiontrees.net/node/21">Tutorial (1): A 
  simple decision tree</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/25">Tutorial (2): 
  Exercise 1</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/26">Tutorial (3): 
  Occam's Razor</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/27">Tutorial (4): 
ID3</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/28">Tutorial (5): 
  Exercise 2</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/29">Tutorial (6): 
  Entropy Bias</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/31">Tutorial (7): 
  Exercise 3</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/32">Tutorial (8): Other 
  Splitting Criteria</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/33">Tutorial (9): 
  Exercise 4</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/34">Tutorial (10): 
  Advanced Topics</A>
  <LI class=leaf><A class=active 
  href="http://decisiontrees.net/node/35">Tutorial (11): Evaluating Decision 
  Trees</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/36">Tutorial (12): 
  Exercise 5</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/37">Tutorial (13): 
  Overfitting</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/44">Tutorial (14): 
  Pruning</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/38">Tutorial (15): 
  Exercise 6</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/39">Tutorial (16): 
  Further Topics</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/40">Tutorial (17): 
  Conclusion</A></LI></UL></DIV></DIV></DIV>
<DIV class="block block-user" id=block-user-1>
<H2>Navigation</H2>
<DIV class=content>
<DIV class=menu>
<UL>
  <LI class=collapsed><A href="http://decisiontrees.net/node/add"><SPAN 
  class=lw1>create content</SPAN></A> </LI></UL></DIV></DIV></DIV>
<DIV class="block block-forum" id=block-forum-0>
<H2>Active forum topics</H2>
<DIV class=content>
<DIV class=item-list>
<UL>
  <LI><A href="http://decisiontrees.net/node/47">Machine Learning Data 
  Sets</A></LI></UL></DIV>
<DIV class=more-link><A title="Read the latest forum topics." 
href="http://decisiontrees.net/forum">more</A></DIV></DIV></DIV>
<DIV class="block block-comment" id=block-comment-0>
<H2>Recent comments</H2>
<DIV class=content>
<DIV class=item-list>
<UL>
  <LI><A href="http://decisiontrees.net/node/20#comment-17">automatic 
  interaction detection</A><BR>8 weeks 3 days ago
  <LI><A href="http://decisiontrees.net/node/20#comment-16">Data sets</A><BR>8 
  weeks 6 days ago
  <LI><A href="http://decisiontrees.net/node/20#comment-15">CHAID AND 
  AID</A><BR>9 weeks 1 hour ago
  <LI><A href="http://decisiontrees.net/node/20#comment-14">re: CHAID and 
  AID</A><BR>9 weeks 2 hours ago
  <LI><A href="http://decisiontrees.net/node/20#comment-13">CHAID and 
  AID</A><BR>9 weeks 5 hours ago
  <LI><A href="http://decisiontrees.net/node/45#comment-12">Large database 
  decision tree classifiers</A><BR>9 weeks 3 days ago
  <LI><A href="http://decisiontrees.net/node/22#comment-9">Re:See5</A><BR>10 
  weeks 15 hours ago
  <LI><A href="http://decisiontrees.net/node/45#comment-8">Need papers about 
  data mining</A><BR>10 weeks 22 hours ago
  <LI><A href="http://decisiontrees.net/node/22#comment-7">See5</A><BR>10 weeks 
  22 hours ago
  <LI><A href="http://decisiontrees.net/node/20#comment-6">Access 
  problems?</A><BR>10 weeks 22 hours ago</LI></UL></DIV></DIV></DIV>
<DIV class="block block-user" id=block-user-3>
<H2>Who's online</H2>
<DIV class=content>There are currently 0 users and 12 guests 
online.</DIV></DIV></DIV>
<DIV class=main-both id=main>
<DIV class=main-wrap-both id=main-wrap>
<DIV class=mw1>
<DIV class=breadcrumb><A href="http://decisiontrees.net/">Home</A> » <A 
href="http://decisiontrees.net/node/16"><SPAN 
class=lw1>Tutorial</SPAN></A></DIV>
<H2 class=main-title>Tutorial (11): Evaluating Decision Trees</H2><!-- begin content -->
<DIV class=node>
<DIV class=content>
<H1>Decision Trees Tutorial &gt; Evaluating decision trees</H1>
<H2>How can we measure how good a decision tree is?</H2>
<P>We have seen so far that there are differing approaches in constructing 
decision trees which lead to quite different trees being produced. There are 
several criteria that we can use in order to evaluate one decision tree 
algorithm for a given dataset over another algorithm on the same dataset. We 
might be interested in how concise the decision tree is that the algorithm 
produces- as we may want to be able to easily understand the rules from the 
tree. We might also look at how fast an algorithm is. <SPAN 
class=titles>Generally though, we will be interested in an algorithm's learning 
ability or how accurate it's predictions are. </SPAN>In this case, we need to 
look at some measures that evaluate a given tree's performance in classifiying 
previously unseen instances from a given problem. We cannot base a measure of 
the tree's accuracy on how well it performs on the training set, as this has 
been used in constructing the tree! There are several techniques that we can 
use. </P>
<H3>Holdout sets</H3>
<P>In some cases where the dataset is relatively small, it is necessary to set 
some of the training data aside in order to use it as test data. This allows us 
to see the accuracy of a tree on hitherto unseen samples. In this situation we 
must be careful to ensure that the data used for training is representative of 
the underlying function or distribution. For instance, we may have a situation 
whereby one class is totally underrepresented in the training data and so error 
rates will be high when we come to use the test data on the tree built from this 
training data. In order to avoid this, random sampling can be used to ensure a 
more balanced representation of all possible classes seen in the dataset. This 
technique is known as stratified holdout and can be used to lessen the effect of 
any bias in the data of one particular class. This method can be explored in the 
<A class=normallink href="http://decisiontrees.net/node/36">next exercise</A>. 
Here you can specify a holdout testing set and then see misclassfication rates 
on this set.</P>
<H3>K-fold cross validation</H3>
<P>In order to confidently lessen the effects of algorithmic bias, a way of 
performing repeated training and testing is possible. This often used procedure 
involves splitting the training data into equally sized mutually exclusive 
subsets or folds. Each one of the subsets is then used in turn as a testing set 
after all the other sets combined have been the training set on which a tree has 
been built. This cross validation procedure allows mean error rates to be 
calculated which gives a useful insight into tree accuracy.</P>
<H3>Leave 1 out validation</H3>
<P>This technique is simply k-fold cross validation whereby k is the number of 
data instances. This has the advantage of allowing the largest amount of 
training data to be used in each run and conversely means that the testing 
procedure is deterministic. With large datasets this is computationally 
infeasible however and in certain situations the deterministic nature of the 
testing results in weird errors.</P>
<H3>Bootstrapping</H3>
<P>The central idea behind this method of validation is one underpinned by the 
statistical technique of sampling with replacement. Here a testing set is chosen 
from instances of the training set that are replaced once chosen. Error rates 
for training and testing sets are then combined to give a truer representation 
of the actual error. This method has been proposed in the form of the .632 
bootstrap which involves taking 63.2% of the training data (which could include 
duplicates that have already been chosen) and using it in testing.</P>
<P>The <A class=normallink href="http://decisiontrees.net/node/36">next 
exercise</A> will use the technique of holdout sets to check classification 
errors. See what type of trees will result in the fewest classification errors. 
</P>
<DIV class=book>
<DIV class=nav>
<DIV class=links>
<DIV class=prev><A title="View the previous page." 
href="http://decisiontrees.net/node/34">previous</A></DIV>
<DIV class=next><A title="View the next page." 
href="http://decisiontrees.net/node/36">next</A></DIV>
<DIV class=up><A title="View this page's parent section." 
href="http://decisiontrees.net/node/16">up</A></DIV></DIV>
<DIV class=titles>
<DIV class=prev>Tutorial (10): Advanced Topics</DIV>
<DIV class=next>Tutorial (12): Exercise 5</DIV></DIV></DIV></DIV></DIV>
<DIV class=links><A 
title="Show a printer-friendly version of this book page and its sub-pages." 
href="http://decisiontrees.net/book/print/35">printer-friendly version</A> – <A 
title="Share your thoughts and opinions related to this posting." 
href="http://decisiontrees.net/comment/reply/35#comment">add new 
comment</A></DIV></DIV><A id=comment></A>
<FORM action=comment method=post>
<DIV><INPUT type=hidden value=35 name=edit[nid]> </DIV></FORM><!-- end content -->
<DIV class=footer-both id=footer>
<P>
<SCRIPT type=text/javascript><!--
google_ad_client = "pub-5329483376432160";
google_ad_width = 468;
google_ad_height = 60;
google_ad_format = "468x60_as";
google_ad_type = "text";
google_ad_channel ="";
google_color_border = "336699";
google_color_bg = "FFFFFF";
google_color_link = "CF094A";
google_color_url = "8BAEC9";
google_color_text = "000000";
//--></SCRIPT>

<SCRIPT 
src="Tutorial (11) Evaluating Decision Trees  Decision Trees_files/show_ads.js" 
type=text/javascript>
</SCRIPT>
</P></DIV></DIV></DIV></DIV></DIV>
<DIV class=sidebar id=sidebar-right>
<DIV class="block block-block" id=block-block-1>
<H2 class=first>Adverts</H2>
<DIV class=content><BR>
<SCRIPT type=text/javascript><!--
google_ad_client = "pub-5329483376432160";
google_ad_width = 160;
google_ad_height = 600;
google_ad_format = "160x600_as";
google_ad_type = "text_image";
google_ad_channel ="8309837109";
google_color_border = "336699";
google_color_bg = "FFFFFF";
google_color_link = "CF094A";
google_color_url = "8BAEC9";
google_color_text = "000000";
//--></SCRIPT>
<BR>
<SCRIPT 
src="Tutorial (11) Evaluating Decision Trees  Decision Trees_files/show_ads.js" 
type=text/javascript>
</SCRIPT>
<BR></DIV></DIV></DIV><SPAN 
class=clear></SPAN></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV>
<DIV class=end-both id=end>
<DIV class=ew1>
<DIV class=ew2></DIV></DIV></DIV></BODY></HTML>
