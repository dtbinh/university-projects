<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3c.org/TR/1999/REC-html401-19991224/loose.dtd">
<!-- saved from url=(0032)http://decisiontrees.net/node/32 -->
<HTML lang=en xml:lang="en" xmlns="http://www.w3.org/1999/xhtml"><HEAD><TITLE>Tutorial (8): Other Splitting Criteria | Decision Trees</TITLE>
<META http-equiv=Content-Style-Type content=text/css>
<META http-equiv=Content-Type content="text/html; charset=utf-8">
<STYLE type=text/css media=all>@import url( misc/drupal.css );
</STYLE>

<STYLE type=text/css media=all>@import url( themes/friendselectric/style.css );
</STYLE>

<SCRIPT type=text/javascript> </SCRIPT>

<META content="MSHTML 6.00.2900.2873" name=GENERATOR></HEAD>
<BODY>
<DIV class=bw1>
<DIV class=bw2>
<DIV id=body-wrap>
<DIV id=header>
<DIV class=hw1>
<DIV class=hw2><A title="Index Page" href="http://decisiontrees.net/"><IMG 
id=site-logo alt=Logo 
src="Tutorial (8) Other Splitting Criteria  Decision Trees_files/logo.png"></A> 
<H1 class=without-slogan id=site-name><A title="Index Page" 
href="http://decisiontrees.net/">Decision Trees</A></H1>
<DIV id=top-nav>
<UL id=primary>
  <LI><A title="Interactive tutorial" 
  href="http://decisiontrees.net/node/16"><SPAN class=lw1><SPAN 
  class=lw2>Tutorial</SPAN></SPAN></A> </LI>
  <LI><A title=Books href="http://decisiontrees.net/node/19"><SPAN 
  class=lw1><SPAN class=lw2>Books</SPAN></SPAN></A> </LI>
  <LI><A title=Software href="http://decisiontrees.net/node/22"><SPAN 
  class=lw1><SPAN class=lw2>Software</SPAN></SPAN></A> </LI>
  <LI><A title=Sites href="http://decisiontrees.net/node/23"><SPAN 
  class=lw1><SPAN class=lw2>Sites</SPAN></SPAN></A> </LI>
  <LI><A title=Papers href="http://decisiontrees.net/node/45"><SPAN 
  class=lw1><SPAN class=lw2>Papers</SPAN></SPAN></A> </LI>
  <LI><A title=Forums href="http://decisiontrees.net/forum"><SPAN 
  class=lw1><SPAN class=lw2>Forums</SPAN></SPAN></A> </LI>
  <LI><A title=About href="http://decisiontrees.net/node/42"><SPAN 
  class=lw1><SPAN class=lw2>About</SPAN></SPAN></A> 
</LI></UL></DIV></DIV></DIV></DIV>
<DIV class=content-both id=content>
<DIV class=cw1>
<DIV class=cw2>
<DIV class=cw3>
<DIV class=cw4>
<DIV class=cw5>
<DIV class=cw6>
<DIV class=cw7>
<DIV class=cw8>
<DIV class=content-wrap-both id=content-wrap>
<DIV class=sidebar id=sidebar-left>
<DIV class="block block-user" id=block-user-0>
<H2 class=first>User login</H2>
<DIV class=content>
<FORM action=user/login?destination=node%2F32 method=post>
<DIV class=user-login-block>
<DIV class=form-item><LABEL for=edit-name>Username:</LABEL><BR><INPUT 
class=form-text id=edit-name maxLength=64 size=15 name=edit[name]> </DIV>
<DIV class=form-item><LABEL for=edit-pass>Password:</LABEL><BR><INPUT 
class=form-password id=edit-pass type=password maxLength=64 size=15 
name=edit[pass]> </DIV><INPUT class=form-submit type=submit value="Log in" name=op> </DIV></FORM>
<DIV class=item-list>
<UL>
  <LI><A title="Create a new user account." 
  href="http://decisiontrees.net/user/register">Create new account</A>
  <LI><A title="Request new password via e-mail." 
  href="http://decisiontrees.net/user/password">Request new 
password</A></LI></UL></DIV></DIV></DIV>
<DIV class="block block-book" id=block-book-0>
<H2>Tutorial</H2>
<DIV class=content>
<DIV class=menu>
<UL>
  <LI class=leaf><A href="http://decisiontrees.net/node/21">Tutorial (1): A 
  simple decision tree</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/25">Tutorial (2): 
  Exercise 1</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/26">Tutorial (3): 
  Occam's Razor</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/27">Tutorial (4): 
ID3</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/28">Tutorial (5): 
  Exercise 2</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/29">Tutorial (6): 
  Entropy Bias</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/31">Tutorial (7): 
  Exercise 3</A>
  <LI class=leaf><A class=active 
  href="http://decisiontrees.net/node/32">Tutorial (8): Other Splitting 
  Criteria</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/33">Tutorial (9): 
  Exercise 4</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/34">Tutorial (10): 
  Advanced Topics</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/35">Tutorial (11): 
  Evaluating Decision Trees</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/36">Tutorial (12): 
  Exercise 5</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/37">Tutorial (13): 
  Overfitting</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/44">Tutorial (14): 
  Pruning</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/38">Tutorial (15): 
  Exercise 6</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/39">Tutorial (16): 
  Further Topics</A>
  <LI class=leaf><A href="http://decisiontrees.net/node/40">Tutorial (17): 
  Conclusion</A></LI></UL></DIV></DIV></DIV>
<DIV class="block block-user" id=block-user-1>
<H2>Navigation</H2>
<DIV class=content>
<DIV class=menu>
<UL>
  <LI class=collapsed><A href="http://decisiontrees.net/node/add"><SPAN 
  class=lw1>create content</SPAN></A> </LI></UL></DIV></DIV></DIV>
<DIV class="block block-forum" id=block-forum-0>
<H2>Active forum topics</H2>
<DIV class=content>
<DIV class=item-list>
<UL>
  <LI><A href="http://decisiontrees.net/node/47">Machine Learning Data 
  Sets</A></LI></UL></DIV>
<DIV class=more-link><A title="Read the latest forum topics." 
href="http://decisiontrees.net/forum">more</A></DIV></DIV></DIV>
<DIV class="block block-comment" id=block-comment-0>
<H2>Recent comments</H2>
<DIV class=content>
<DIV class=item-list>
<UL>
  <LI><A href="http://decisiontrees.net/node/20#comment-17">automatic 
  interaction detection</A><BR>8 weeks 3 days ago
  <LI><A href="http://decisiontrees.net/node/20#comment-16">Data sets</A><BR>8 
  weeks 6 days ago
  <LI><A href="http://decisiontrees.net/node/20#comment-15">CHAID AND 
  AID</A><BR>9 weeks 1 hour ago
  <LI><A href="http://decisiontrees.net/node/20#comment-14">re: CHAID and 
  AID</A><BR>9 weeks 2 hours ago
  <LI><A href="http://decisiontrees.net/node/20#comment-13">CHAID and 
  AID</A><BR>9 weeks 5 hours ago
  <LI><A href="http://decisiontrees.net/node/45#comment-12">Large database 
  decision tree classifiers</A><BR>9 weeks 3 days ago
  <LI><A href="http://decisiontrees.net/node/22#comment-9">Re:See5</A><BR>10 
  weeks 15 hours ago
  <LI><A href="http://decisiontrees.net/node/45#comment-8">Need papers about 
  data mining</A><BR>10 weeks 22 hours ago
  <LI><A href="http://decisiontrees.net/node/22#comment-7">See5</A><BR>10 weeks 
  22 hours ago
  <LI><A href="http://decisiontrees.net/node/20#comment-6">Access 
  problems?</A><BR>10 weeks 22 hours ago</LI></UL></DIV></DIV></DIV>
<DIV class="block block-user" id=block-user-3>
<H2>Who's online</H2>
<DIV class=content>There are currently 0 users and 13 guests 
online.</DIV></DIV></DIV>
<DIV class=main-both id=main>
<DIV class=main-wrap-both id=main-wrap>
<DIV class=mw1>
<DIV class=breadcrumb><A href="http://decisiontrees.net/">Home</A> » <A 
href="http://decisiontrees.net/node/16"><SPAN 
class=lw1>Tutorial</SPAN></A></DIV>
<H2 class=main-title>Tutorial (8): Other Splitting Criteria</H2><!-- begin content -->
<DIV class=node>
<DIV class=content>
<H1>Decision Trees tutorial &gt; Other splitting methods </H1>
<P>The observation that Information Gain is unfairly biased has led to other 
splitting criteria being proposed.</P>
<H3>Gain Ratio</H3>
<P>An obvious way to negate the bias or "greediness" of Information Gain is to 
take into account the number of values of an attribute. This is exactly the 
approach that can be used. A new, improved calculation for attribute A over data 
S is:</P>
<P align=center><IMG height=62 alt="Gain Ratio (S,A) = Gain(S,A)/IV(A)" 
src="Tutorial (8) Other Splitting Criteria  Decision Trees_files/gainratioEq.gif" 
width=317></P>
<P align=center><IMG height=65 alt=IV(A)=sum(-log2pi/N) 
src="Tutorial (8) Other Splitting Criteria  Decision Trees_files/ivEq.gif" 
width=240></P>
<P align=left>The second equation for IV (A) measures the information content 
for the attribute A by looking at each proportion, p, of instances that take 
value i for the attribute. </P>
<P>Try the practical exercise on the <A class=normallink 
href="http://decisiontrees.net/node/33">next page</A> to see how gain ratio 
differs from information gain.</P>
<H3>GINI</H3>
<P>A method used by the influential CART system that was developed in the 1980s 
(see Breiman, L., Freidman, J., Olshen, R., and Stone, C., 1984. Classification 
and regression trees. Wadsworth International, CA).</P>
<H3>Statistical Approaches</H3>
<P>A lot of the modern algorithms use some information-based measures adapted 
from Information Gain. However other methods involve the use of statistical 
approaches which base their tree induction algorithms on the distribution of the 
data. In particular, measures adopted from the classic statistical technique of 
chi-squared are used. This measures the amount of correlation between two 
variables. We use correlation tables to calculate this. As an example, here is 
the correlation table for the attribute Income from the Marketing data:</P>
<TABLE id=dataTable width=200 align=center border=0>
  <TBODY>
  <TR>
    <TD>&nbsp;</TD>
    <TD>&nbsp;</TD>
    <TD colSpan=2><SPAN class=titles>Class</SPAN></TD>
    <TD>&nbsp;</TD>
    <TD>&nbsp;</TD>
    <TD>&nbsp;</TD></TR>
  <TR>
    <TD vAlign=center rowSpan=4>
      <P><SPAN class=titles>Income</SPAN></P></TD>
    <TD>&nbsp;</TD>
    <TD>Responded</TD>
    <TD>Nothing</TD>
    <TD><SPAN class=titles>Totals</SPAN></TD>
    <TD colSpan=2 rowSpan=4>&nbsp;</TD></TR>
  <TR>
    <TD>High</TD>
    <TD>3</TD>
    <TD>4</TD>
    <TD>7</TD></TR>
  <TR>
    <TD>Low</TD>
    <TD>6</TD>
    <TD>1</TD>
    <TD>7</TD></TR>
  <TR>
    <TD><SPAN class=titles>Totals</SPAN></TD>
    <TD>9</TD>
    <TD>5</TD>
    <TD>14</TD></TR></TBODY></TABLE>
<P align=left>This table shows the class distributions for each instance 
according to their Income value. The totals are in the last column and row. We 
calculate the chi-squared distribution from the following formula:</P>
<P align=center><IMG height=71 alt=Chi-squared 
src="Tutorial (8) Other Splitting Criteria  Decision Trees_files/chiEq.gif" 
width=196></P>
<P align=left>Calculating this for our Income attribute gives:</P>
<P align=center><IMG height=61 alt="Chi-squared(Income) = 3.7" 
src="Tutorial (8) Other Splitting Criteria  Decision Trees_files/chiCalc.gif" 
width=492> </P>
<P align=left>For the other attributes the (normalised) chi-squared values 
are:</P>
<UL>
  <LI>Date = 9.3333 
  <LI>District = 4.4 
  <LI>House Type = 2 
  <LI>Previous Customer = 2 </LI></UL>
<P align=left>The higher the value, the more correlation there is between the 
target attribute and the attribute used in the calculation. </P>
<P align=left>Although the Date attribute is still favoured, it is not quite as 
highly favoured (relatively) compared with the evaulation technique of 
information gain (see the <A class=normallink 
href="http://decisiontrees.net/node/31">last exercise</A>). </P>
<H3>Other Methods</H3>
<P>Several other variations have been proposed such as <SPAN 
class=titles>permutation tests</SPAN> (Frank &amp; Witten 98) and <SPAN 
class=titles>multivariate splits</SPAN>. </P>
<P><STRONG>References</STRONG> </P>
<P><STRONG>Mingers, J. 1989. An Empirical Comparison of Selection Measures for 
Decision-Tree Induction. Machine Learning 3: 319-342.<BR>Frank, E., Witten, I., 
1998. Using a permutation test for attribute selection in decision 
trees.</STRONG></P>
<DIV class=book>
<DIV class=nav>
<DIV class=links>
<DIV class=prev><A title="View the previous page." 
href="http://decisiontrees.net/node/31">previous</A></DIV>
<DIV class=next><A title="View the next page." 
href="http://decisiontrees.net/node/33">next</A></DIV>
<DIV class=up><A title="View this page's parent section." 
href="http://decisiontrees.net/node/16">up</A></DIV></DIV>
<DIV class=titles>
<DIV class=prev>Tutorial (7): Exercise 3</DIV>
<DIV class=next>Tutorial (9): Exercise 4</DIV></DIV></DIV></DIV></DIV>
<DIV class=links><A 
title="Show a printer-friendly version of this book page and its sub-pages." 
href="http://decisiontrees.net/book/print/32">printer-friendly version</A> – <A 
title="Share your thoughts and opinions related to this posting." 
href="http://decisiontrees.net/comment/reply/32#comment">add new 
comment</A></DIV></DIV><A id=comment></A>
<FORM action=comment method=post>
<DIV><INPUT type=hidden value=32 name=edit[nid]> </DIV></FORM><!-- end content -->
<DIV class=footer-both id=footer>
<P>
<SCRIPT type=text/javascript><!--
google_ad_client = "pub-5329483376432160";
google_ad_width = 468;
google_ad_height = 60;
google_ad_format = "468x60_as";
google_ad_type = "text";
google_ad_channel ="";
google_color_border = "336699";
google_color_bg = "FFFFFF";
google_color_link = "CF094A";
google_color_url = "8BAEC9";
google_color_text = "000000";
//--></SCRIPT>

<SCRIPT 
src="Tutorial (8) Other Splitting Criteria  Decision Trees_files/show_ads.js" 
type=text/javascript>
</SCRIPT>
</P></DIV></DIV></DIV></DIV></DIV>
<DIV class=sidebar id=sidebar-right>
<DIV class="block block-block" id=block-block-1>
<H2 class=first>Adverts</H2>
<DIV class=content><BR>
<SCRIPT type=text/javascript><!--
google_ad_client = "pub-5329483376432160";
google_ad_width = 160;
google_ad_height = 600;
google_ad_format = "160x600_as";
google_ad_type = "text_image";
google_ad_channel ="8309837109";
google_color_border = "336699";
google_color_bg = "FFFFFF";
google_color_link = "CF094A";
google_color_url = "8BAEC9";
google_color_text = "000000";
//--></SCRIPT>
<BR>
<SCRIPT 
src="Tutorial (8) Other Splitting Criteria  Decision Trees_files/show_ads.js" 
type=text/javascript>
</SCRIPT>
<BR></DIV></DIV></DIV><SPAN 
class=clear></SPAN></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV>
<DIV class=end-both id=end>
<DIV class=ew1>
<DIV class=ew2></DIV></DIV></DIV></BODY></HTML>
